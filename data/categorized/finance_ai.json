[
  {
    "title": "Google to scale up AI-powered fraud detection and security operations in India",
    "content": "Latest\nAI\nAmazon\nApps\nBiotech & Health\nClimate\nCloud Computing\nCommerce\nCrypto\nEnterprise\nEVs\nFintech\nFundraising\nGadgets\nGaming\nGoogle\nGovernment & Policy\nHardware\nInstagram\nLayoffs\nMedia & Entertainment\nMeta\nMicrosoft\nPrivacy\nRobotics\nSecurity\nSocial\nSpace\nStartups\nTikTok\nTransportation\nVenture\nEvents\nStartup Battlefield\nStrictlyVC\nNewsletters\nPodcasts\nVideos\nPartner Content\nTechCrunch Brand Studio\nCrunchboard\nContact Us\nGoogle has unveiled its Safety Charter in India, which will expand its AI-led developments for fraud detection and combating scams across the country, the company’s largest market outside the United States.\nDigital fraud in India is rising. Fraud related to the Indian government’s instant payment system UPIgrew 85% year-over-yearto nearly 11 billion Indian rupees ($127 million) last year, per the government’s data. India also saw several instances of digital arrest scams, where fraudsters pose as officials to extort money via video calls and predatory loan apps.\nWith its Safety Charter, Google aims to address some of these areas. The company has also launched itssecurity engineering centerin India, its fourth center after Dublin, Munich, and Malaga.\nAnnounced at the Google for India summit last year, the security engineering center (GSec) will allow Google to partner with the local community, including government, academia and students, and small and medium enterprises to create solutions to solve cybersecurity, privacy, safety, and AI problems, said Google VP of security engineering Heather Adkins in an interview with TechCrunch.\nGoogle has partnered with the Ministry of Home Affairs’ Indian Cyber Crime Coordination Centre (I4C) to raise awareness of cybercrimes, the company said in a blog post. This builds upon the company’s existing work, including the launch of its online fraud identification program,DigiKavach, which debuted in 2023 to restrict the harmful effects of malicious financial apps and predatory loan apps.\nWith its GSec in India, Google will focus on three key areas, Adkins told TechCrunch: the phenomenon of online scams and fraud and how people are safe online; the cybersecurity of enterprises, government, and critical infrastructure; and building responsible AI.\n“These three areas will become part of our safety charter for India, and over the coming years… we want to use the fact that we have engineering capability here to solve for what’s happening in India, close to where the users are,” said Adkins.\nGlobally, Google is utilizing AI to combat online scams and remove millions of ads and ad accounts. The company aims to deploy AI more extensively in India to combat digital fraud.\nGoogle Messages, which comes preinstalled on many Android devices, uses AI-powered Scam Detection that has helped protect users from over 500 million suspicious messages a month. Similarly, Googlepiloted its Play Protectin India last year, which it claims has blocked nearly 60 million attempts to install high-risk apps, resulting in the stopping of more than 220,000 unique apps on over 13 million devices. Google Pay, which isone of the top UPI-based payment appsin the country, also displayed 41 million warnings against transactions suspected to be potential scams.\n—\nAdkins, a founding member of Google’s security team who has been part of the internet company for over 23 years, discussed several other topics during an interview with TechCrunch:\nAdkins said one thing top of mind is the use and misuse of AI by malicious actors.\n“We’re obviously tracking AI very closely, and up until now, we’ve mostly seen the large language models like Gemini used as productivity enhancements. For example, to make phishing scams a bit more effective — especially if the actor and the target have different languages — they can use the benefit of translation to make the scams more believable using deepfakes, images, video, etc.,” said Adkins.\nAdkins said Google is conducting extensive testing of its AI models to ensure they understand what they should not do.\n“This is important for generated content that might be harmful, but also actions that it might take,” said Akins.\nGoogle is working on frameworks, including theSecure AI Framework, to restrict the abuse of its Gemini models. However, to protect generative AI from being misused and abused by hackers in the future, the company sees the need for a framework to build safety for how multiple agents communicate.\n“The industry is moving very, very quickly [by] putting protocols out. It’s almost like the early days of the internet, where everybody’s releasing code in real time, and we’re thinking about safety after the fact,” said Adkins.\nGoogle does not want to introduce merely its own frameworks to limit the scope of generative AI being abused by hackers. Instead, Adkins said the company is working with the research community and developers.\n“One of the things you don’t want to do is constrain yourself too much in the early research days,” said Adkins.\nAlongside generative AI’s potential for abuse by hackers, Adkins sees commercial surveillance vendors as a significant threat. These can include spyware makers, includingNSO Group, which isinfamous for its Pegasus spyware, or other small enterprises selling surveillance tools.\n“These are companies spun up all over the world, and they develop and make and sell a platform for hacking,” said Adkins. “You might pay $20, you might pay $200,000, just depending on the sophistication of the platform, and it allows you to scale attacking people without any expertise on your own.”\nSome of these vendors also sell their tools tospy on people in markets, including India. However, apart from being targeted by surveillance tools, the country has its own unique challenges in part for its size. The country sees not only AI-led deepfakes and voice cloning frauds, but also instances ofdigital arrests, which Adkins underlines are just regular scams adapted for the digital world.\n“You can see how quickly the threat actors themselves are advancing… I love studying cyber in this region because of that. It’s often a hint of what we’re going to see worldwide at some point,” said Adkins.\nGoogle has long encouraged its users to use more secure authentication methods beyond passwords to protect their online presence. The company switched on multi-factor authentication (MFA) for all user accounts in the past, and also promotes hardware-based security keys, which Adkins mentioned by pointing to its employees actively using their laptops. Passwordless is alsobecoming a popular tech term, with various meanings.\nNonetheless, expecting people to abandon passwords in a market like India is hard due to its vast demographics and diverse economic landscape.\n“We knew for a very long time that passwords were not secure. This concept of a multi-factor authentication was a step forward,” said Adkins, adding that Indians likely favor SMS-based authentication over other MFA options.\nTopics\nReporter\nFrom seed to Series C and beyond—founders and VCs of all stages are heading to Boston. Be part of the conversation. Save $200+ now and tap into powerful takeaways, peer insights, and game-changing connections.\nGoogle to scale up AI-powered fraud detection and security operations in India\nSpotify’s Daniel Ek just bet bigger on Helsing, Europe’s defense tech darling\nYou can now set up double dates with friends on Tinder\nThe cracks in the OpenAI-Microsoft relationship are reportedly widening\nFinland warms up the world’s largest sand battery, and the economics look appealing\nInstagram tests a reposts feature\nInstagram users complain of mass bans, pointing finger at AI\n© 2025 TechCrunch Media LLC.",
    "url": "https://techcrunch.com/2025/06/17/google-to-scale-up-ai-powered-fraud-detection-and-security-operations-in-india/",
    "source": {
      "name": "TechCrunch"
    },
    "publishedAt": "2025-06-17T07:01:00Z",
    "is_relevant": true,
    "category": "finance_ai",
    "score": 9.0
  }
]